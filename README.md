ğŸš€ Overview
This project demonstrates how to build a spam classifier by:

Preprocessing message text (tokenize, lowercase, remove stopwords/non-English, lemmatize).

Training or loading Word2Vec embeddings (via Gensim).

Aggregating word vectors into sentence-level vectors.

Applying a classifier (e.g. Naive Bayes, SVM, Random Forest) on those sentence embeddings.

Evaluating the model performance.

ğŸ“ Repository Structure
â”œâ”€â”€ data/                 # (Optional) Raw & preprocessed datasets
â”œâ”€â”€ notebooks/           # Jupyter notebooks for experiments
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py     # Text cleaning & tokenization
â”‚   â”œâ”€â”€ train_embeddings.py # Train/load Word2Vec
â”‚   â”œâ”€â”€ vectorize.py       # Sentence-level aggregation
â”‚   â”œâ”€â”€ train_model.py     # Train classifier
â”‚   â””â”€â”€ evaluate.py        # Evaluate & report metrics
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ README.md             # This file
â””â”€â”€ LICENSE               # Project license

âš™ï¸ Installation & Setup
Clone the repo
git clone https://github.com/ShivamMitra/Spam-Ham-Project-Using-Word-2Vec.git
cd Spam-Ham-Project-Using-Word-2Vec
Create Python virtual environment

python3 -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows
Install dependencies

pip install -r requirements.txt
Download NLTK data (if used)

python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"

ğŸ’¡ Usage
1. Prepare your data
Place raw text in data/raw/

Use preprocess.py to tokenize, clean, and save results to data/processed/

Example:

python src/preprocess.py \
  --input data/raw/messages.csv \
  --output data/processed/messages_cleaned.csv
2. Train or load embeddings
Train a fresh Word2Vec model:

python src/train_embeddings.py \
  --input data/processed/messages_cleaned.csv \
  --model-path models/word2vec.model
Or load pretrained embeddings:

python src/train_embeddings.py \
  --load-model models/word2vec.model
3. Create sentence-level vectors
python src/vectorize.py \
  --model models/word2vec.model \
  --input data/processed/messages_cleaned.csv \
  --output data/features/message_vectors.npz
4. Train classification model
python src/train_model.py \
  --input data/features/message_vectors.npz \
  --algo svm \
  --model-out models/spam_classifier.pkl
Supports algorithms like: naive_bayes, svm, random_forest.

5. Evaluate performance
python src/evaluate.py \
  --model models/spam_classifier.pkl \
  --vectors data/features/message_vectors.npz
Expected metrics: accuracy, precision, recall, F1-score, confusion matrix.

